st.title("üìä Chat with Your Data")
st.subheader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!")

uploaded_file = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV", type=["csv"])

if uploaded_file is not None:
    st.success("‚úÖ ‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

    # (‡πÇ‡∏Ñ‡πâ‡∏î‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡πà‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô Pandas dataframe, ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á, ‡∏Å‡∏£‡∏≤‡∏ü, ‡πÅ‡∏•‡∏∞ QA)
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
import streamlit as st
import pandas as pd
import google.generativeai as genai

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Gemini API
genai.configure(api_key=st.secrets.get("GEMINI_API_KEY", "your-gemini-key"))

# 2. ‡πÇ‡∏´‡∏•‡∏î Model
model = genai.GenerativeModel(
    model_name="gemini-1.5-pro",
    system_instruction="‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CSV ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å ‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•"
)

# 3. Session state
if "chat" not in st.session_state:
    st.session_state.chat = None
if "df_summary" not in st.session_state:
    st.session_state.df_summary = ""
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

# 4. UI
st.set_page_config(page_title="CSV Gemini Chatbot", layout="centered")
st.title("üí¨ C (sv) mini")

st.markdown(
    "<div style='font-size: 1.2rem; font-weight: 500;'>One Upload. Your Questions, My Sharp Insights ‚Äî Powered by Gemini.</div>",
    unsafe_allow_html=True
)

st.markdown("&nbsp;<br>", unsafe_allow_html=True)


# 5. Upload CSV
# 5. Upload CSV
st.markdown('<p style="font-size:16px;">üìÅ Please upload your CSV file.</p>', unsafe_allow_html=True)
uploaded_file = st.file_uploader("", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("üìä Preview of the information in the file.")
    st.dataframe(df.head())

    # ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•
    summary_text = f"""
‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î:
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß: {df.shape[0]} ‡πÅ‡∏ñ‡∏ß
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {df.shape[1]} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
- ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {', '.join(df.columns)}
- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å:
{df.head().to_string(index=False)}
"""
    st.session_state.df_summary = summary_text

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á session ‡πÅ‡∏ä‡∏ó
    st.session_state.chat = model.start_chat(
        history=[
            {"role": "user", "parts": [summary_text]},
            {"role": "model", "parts": ["I‚Äôve reviewed the data. Feel free to ask me anything about it üôÇ"]}
        ]
    )
    st.success(" ‚úÖ Ready to Talk. Do you need a hand with anything?")

# 6. ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó
for msg in st.session_state.chat_log:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 7. ‡πÅ‡∏ä‡∏ó
if st.session_state.chat:
    prompt = st.chat_input("Ask me anything about the CSV file.")
    if prompt:
        st.chat_message("user").markdown(prompt)
        st.session_state.chat_log.append({"role": "user", "content": prompt})

        try:
            response = st.session_state.chat.send_message(prompt)
            st.chat_message("assistant").markdown(response.text)
            st.session_state.chat_log.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
